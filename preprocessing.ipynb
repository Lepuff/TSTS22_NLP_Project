{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels(doc, labels:list):\n",
    "        text_no_locations = ''\n",
    "        for token in doc:\n",
    "            if token.ent_type_ not in labels:\n",
    "                text_no_locations += token.text\n",
    "                if token.whitespace_:\n",
    "                    text_no_locations += ' '\n",
    "        return text_no_locations\n",
    "\n",
    "def retrieve_tokens(row, pos_to_remove, labels_to_remove):\n",
    "    return [token.lemma_.lower() for token in row if token.pos_ not in pos_to_remove \n",
    "                                                                      and not token.is_stop \n",
    "                                                                      and token.is_alpha \n",
    "                                                                      and token.ent_type_ not in labels_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_input(row):\n",
    "    # Remove unicode and webpages\n",
    "    regexp4 = r'\\b(?<![\\\\\\.])\\w+(?!\\.\\w+)\\b'\n",
    "\n",
    "\n",
    "    result = BeautifulSoup(row, 'lxml').get_text()\n",
    "    result = re.findall(regexp4, result)\n",
    "\n",
    "    return \" \".join(result)\n",
    "\n",
    "def process_input(df):\n",
    "    nlp = spacy.load(\"sv_core_news_sm\")\n",
    "\n",
    "    #labels_to_remove = ['TME', 'MSR']\n",
    "    labels_to_remove = ['TME']\n",
    "    pos_to_remove = ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n",
    "\n",
    "    token_list = []\n",
    "    unique_token_list = []\n",
    "    entity_list = []\n",
    "    label_list = []\n",
    "    text_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        doc_text = nlp(row['Text'])\n",
    "        doc_title = nlp(row['Title'])\n",
    "        \n",
    "        doc_ents = doc_text.ents + doc_title.ents\n",
    "\n",
    "        title_tokens = retrieve_tokens(doc_title, pos_to_remove, labels_to_remove)\n",
    "        text_tokens = retrieve_tokens(doc_text, pos_to_remove, labels_to_remove)\n",
    "        \n",
    "        doc_tokens = title_tokens + text_tokens\n",
    "        unique_doc_tokens = set(doc_tokens)\n",
    "        # Remove duplicate entities from the list\n",
    "        unique_ents = list({keyword.__repr__(): keyword for keyword in doc_ents}.values())\n",
    "        \n",
    "        # Remove entities that have label 'TME' or 'LOC' because they are mostly redundant\n",
    "        # And the text will be changed to not contain words with these labels\n",
    "        unique_ents = [ent for ent in unique_ents if not ent.label_ in labels_to_remove]    \n",
    "           \n",
    "        entities = [str(x) for x in unique_ents]\n",
    "        labels = [str(labels.label_) for labels in unique_ents]\n",
    "        \n",
    "        # Remove words that contain the specified labels\n",
    "        label_free_text = remove_labels(doc_text, labels=labels_to_remove)\n",
    "\n",
    "        entity_list.append(entities)\n",
    "        label_list.append(labels)\n",
    "        token_list.append(doc_tokens)\n",
    "        unique_token_list.append(unique_doc_tokens)\n",
    "        \n",
    "        df.at[index,['Text']] = label_free_text\n",
    "        \n",
    "        #if index > 1:\n",
    "        #    break\n",
    "        \n",
    "    df['Entities'] = pd.Series(entity_list)\n",
    "    df['Labels'] = pd.Series(label_list)\n",
    "    df['Tokens'] = pd.Series(token_list)\n",
    "    df['Unique_Tokens'] = pd.Series(unique_token_list)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\strep\\miniconda3\\envs\\nlp\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "\n",
    "if(not exists('preprocessed_articles.csv')):  \n",
    "    df_articles = pd.read_csv('sävsjö_articles.csv')\n",
    "    df_articles = df_articles.dropna().reset_index(drop=True)\n",
    "    df_processed = df_articles.copy()\n",
    "\n",
    "    df_processed['Title'] = df_processed['Title'].apply(lambda x: regex_input(x))\n",
    "    df_processed['Text'] = df_processed['Text'].apply(lambda x: regex_input(x))\n",
    "\n",
    "    df_processed = process_input(df_processed)\n",
    "\n",
    "    df_processed.to_csv('preprocessed_articles.csv')\n",
    "    \n",
    "else:\n",
    "    df_processed = pd.read_csv('preprocessed_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Unique_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Aktiespararna säger ja till Gunvorbudet</td>\n",
       "      <td>Aktiespararna rekommenderar sina medlemmar att...</td>\n",
       "      <td>[Gunvor Group, Rörvik]</td>\n",
       "      <td>[PRS, ORG]</td>\n",
       "      <td>[aktiespararna, gunvorbudet, aktiespararna, re...</td>\n",
       "      <td>{group, medlem, gunvor, aktiespararna, anta, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Man fast i en timme i grop</td>\n",
       "      <td>En man i 60 årsåldern föll ner i en grop som v...</td>\n",
       "      <td>[Sävsjö]</td>\n",
       "      <td>[LOC]</td>\n",
       "      <td>[timme, grop, årsålder, föll, grop, grävd, ege...</td>\n",
       "      <td>{sävsjö, hål, djup, timme, grop, egen, föll, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Mannen fastnade i en grop i flera timmar</td>\n",
       "      <td>En man i 60 årsåldern trillade ner i ett grävt...</td>\n",
       "      <td>[David]</td>\n",
       "      <td>[PRS]</td>\n",
       "      <td>[mannen, fastna, grop, timme, årsålder, trilla...</td>\n",
       "      <td>{hål, grävt, mannen, timme, grop, trilla, fast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>En motorcykel</td>\n",
       "      <td>Här är den längre versionen</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[motorcykel, vara, version]</td>\n",
       "      <td>{vara, motorcykel, version}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66</td>\n",
       "      <td>Stulna braskaminer för 50 000 ska värma</td>\n",
       "      <td>Det börjar bli vinter och kallt Då är det skön...</td>\n",
       "      <td>[Smålandsvillan, Vrigstad]</td>\n",
       "      <td>[ORG, LOC]</td>\n",
       "      <td>[stulna, braskamin, värma, börja, vinter, kall...</td>\n",
       "      <td>{kall, helg, braskamin, vara, försvann, vinter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                     Title  \\\n",
       "0   2   Aktiespararna säger ja till Gunvorbudet   \n",
       "1   7                Man fast i en timme i grop   \n",
       "2   8  Mannen fastnade i en grop i flera timmar   \n",
       "3  56                             En motorcykel   \n",
       "4  66   Stulna braskaminer för 50 000 ska värma   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Aktiespararna rekommenderar sina medlemmar att...   \n",
       "1  En man i 60 årsåldern föll ner i en grop som v...   \n",
       "2  En man i 60 årsåldern trillade ner i ett grävt...   \n",
       "3                        Här är den längre versionen   \n",
       "4  Det börjar bli vinter och kallt Då är det skön...   \n",
       "\n",
       "                     Entities      Labels  \\\n",
       "0      [Gunvor Group, Rörvik]  [PRS, ORG]   \n",
       "1                    [Sävsjö]       [LOC]   \n",
       "2                     [David]       [PRS]   \n",
       "3                          []          []   \n",
       "4  [Smålandsvillan, Vrigstad]  [ORG, LOC]   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [aktiespararna, gunvorbudet, aktiespararna, re...   \n",
       "1  [timme, grop, årsålder, föll, grop, grävd, ege...   \n",
       "2  [mannen, fastna, grop, timme, årsålder, trilla...   \n",
       "3                        [motorcykel, vara, version]   \n",
       "4  [stulna, braskamin, värma, börja, vinter, kall...   \n",
       "\n",
       "                                       Unique_Tokens  \n",
       "0  {group, medlem, gunvor, aktiespararna, anta, r...  \n",
       "1  {sävsjö, hål, djup, timme, grop, egen, föll, l...  \n",
       "2  {hål, grävt, mannen, timme, grop, trilla, fast...  \n",
       "3                        {vara, motorcykel, version}  \n",
       "4  {kall, helg, braskamin, vara, försvann, vinter...  "
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sävsjö kommun ska få en ny skolchef Han heter Stefan Claesson och jobbar just nu i Jönköping När han ska börja basa över läre och elever i Sävsjö är inte klart det är en förhandlingsfråga mellan nye skolchefen och hans hittillsvarande arbetsgivare'"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed['Text'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove empty rows and convert to lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not used so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Check for a value in a dataframe column\"\"\"\n",
    "def check_value(df, column, value):\n",
    "    return df[df[column].str.contains(value, na=False)]\n",
    "check_value(df_processed, 'Entities', 'Smålandsvillan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_test = df_articles[[\"Labels\",\"Entities\"]]\n",
    "\n",
    "for ind, row in df_test.iterrows():\n",
    "    if row[\"Labels\"] == \"[]\":\n",
    "        df_test = df_test.drop(index=ind)\n",
    "\n",
    "df_test[[\"Labels\",\"Entities\"]].apply(lambda x : str(x).split(','))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73e735a07ce367303aaadeabd025808cbfe97e5b002cadee1be2f1eb67320e65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
