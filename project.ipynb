{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_input(input):\n",
    "    #regexp = r'[\\\\\\/\\.,;:()]+\\w*'\n",
    "    #regexp2 = r'\\b(?<![\\\\\\/\\.\\,\\\\:\\;\\(\\)\\+\\-])\\w+\\b'\n",
    "    #regexp3 = r'\\b(?<![\\\\\\/])\\w+\\.*\\w*\\b'\n",
    "\n",
    "    # Remove unicode and webpages\n",
    "    regexp4 = r'\\b(?<![\\\\\\.])\\w+(?!\\.\\w+)\\b'\n",
    "\n",
    "    # Regex for removing words that are preceded by '\\'\n",
    "    unicode_regexp = r'\\b(?<![\\\\])\\w+\\b'\n",
    "\n",
    "    # Regex for removing webpages\n",
    "    webpage_regexp = r'\\b(?<![\\.])\\w+(?!\\.\\w+)\\b'\n",
    "\n",
    "    # Remove html tags, 'lxml' more robust than 'html.parser'\n",
    "    result = BeautifulSoup(input, 'lxml').get_text()\n",
    "    \n",
    "\n",
    "\n",
    "    # Save words that are not preceded by a '\\' and webpages\n",
    "    result = re.findall(regexp4, result)\n",
    "    \n",
    "            # TRYING TO COMBINE MULTIPLE REGEX, WORK IN PROGRESS\n",
    "            #patterns = [unicode_regexp, webpage_regexp]\n",
    "            #pattern = \"|\".join(patterns)  # pattern1|pattern2|pattern3|...\n",
    "            #re.findall(pattern, result)\n",
    "\n",
    "    # Remove excessive whitespaces\n",
    "    result = \" \".join(result)\n",
    "\n",
    "\n",
    "    #result = \" \".join(result.split())\n",
    "   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\repos\\TSTS22_NLP_Project\\project.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df_articles\u001b[39m.\u001b[39mcolumns[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         df_articles[col] \u001b[39m=\u001b[39m df_articles[col]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         df_articles[col] \u001b[39m=\u001b[39m df_articles[col]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: preprocess_input(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     df_processed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mpreprocessed_articles.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1085\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1138\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1143\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1144\u001b[0m             values,\n\u001b[0;32m   1145\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1146\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1147\u001b[0m         )\n\u001b[0;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1150\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\repos\\TSTS22_NLP_Project\\project.ipynb Cell 3\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m df_articles\u001b[39m.\u001b[39mcolumns[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         df_articles[col] \u001b[39m=\u001b[39m df_articles[col]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         df_articles[col] \u001b[39m=\u001b[39m df_articles[col]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: preprocess_input(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     df_processed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mpreprocessed_articles.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\repos\\TSTS22_NLP_Project\\project.ipynb Cell 3\u001b[0m in \u001b[0;36mpreprocess_input\u001b[1;34m(input)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m webpage_regexp \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb(?<![\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.])\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+(?!\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Remove html tags, 'lxml' more robust than 'html.parser'\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m result \u001b[39m=\u001b[39m BeautifulSoup(\u001b[39minput\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mlxml\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mget_text()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Save words that are not preceded by a '\\' and webpages\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m result \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(regexp4, result)\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:248\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     builder_class \u001b[39m=\u001b[39m builder_registry\u001b[39m.\u001b[39mlookup(\u001b[39m*\u001b[39mfeatures)\n\u001b[0;32m    247\u001b[0m     \u001b[39mif\u001b[39;00m builder_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m         \u001b[39mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    249\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a tree builder with the features you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequested: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Do you need to install a parser library?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m             \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(features))\n\u001b[0;32m    253\u001b[0m \u001b[39m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[39m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "\n",
    "if(not exists('preprocessed_articles.csv')):  \n",
    "    df_articles = pd.read_csv('sävsjö_articles.csv')\n",
    "    df_articles = df_articles.dropna()\n",
    "    # columns: ['ID', 'Title', 'Text']\n",
    "    # iterate over 'Title' and 'Text' columns and preprocess the texts\n",
    "    for col in df_articles.columns[1:]:\n",
    "        df_articles[col] = df_articles[col].astype(str)\n",
    "        df_articles[col] = df_articles[col].apply(lambda x: preprocess_input(x))\n",
    "    \n",
    "else:\n",
    "    df_processed = pd.read_csv('preprocessed_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Aktiespararna säger ja till Gunvorbudet</td>\n",
       "      <td>Aktiespararna rekommenderar sina medlemmar att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Man fast i en timme i grop</td>\n",
       "      <td>En man i 60 årsåldern föll ner i en grop som v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Mannen fastnade i en grop i flera timmar</td>\n",
       "      <td>En man i 60 årsåldern trillade ner i ett grävt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>En motorcykel</td>\n",
       "      <td>Här är den längre versionen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66</td>\n",
       "      <td>Stulna braskaminer för 50 000 ska värma</td>\n",
       "      <td>Det börjar bli vinter och kallt Då är det skön...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                     Title  \\\n",
       "0   2   Aktiespararna säger ja till Gunvorbudet   \n",
       "2   7                Man fast i en timme i grop   \n",
       "3   8  Mannen fastnade i en grop i flera timmar   \n",
       "4  56                             En motorcykel   \n",
       "5  66   Stulna braskaminer för 50 000 ska värma   \n",
       "\n",
       "                                                Text  \n",
       "0  Aktiespararna rekommenderar sina medlemmar att...  \n",
       "2  En man i 60 årsåldern föll ner i en grop som v...  \n",
       "3  En man i 60 årsåldern trillade ner i ett grävt...  \n",
       "4                        Här är den längre versionen  \n",
       "5  Det börjar bli vinter och kallt Då är det skön...  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels(doc, labels:list):\n",
    "        text_no_locations = ''\n",
    "        for token in doc:\n",
    "            if token.ent_type_ not in labels:\n",
    "                text_no_locations += token.text\n",
    "                if token.whitespace_:\n",
    "                    text_no_locations += ' '\n",
    "        return text_no_locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Aktiespararna rekommenderar sina medlemmar att...</td>\n",
       "      <td>[Gunvor Group, Rörvik]</td>\n",
       "      <td>[PRS, ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>En man i 60 årsåldern föll ner i en grop som v...</td>\n",
       "      <td>[David]</td>\n",
       "      <td>[PRS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>En man i 60 årsåldern trillade ner i ett grävt...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Här är den längre versionen</td>\n",
       "      <td>[Smålandsvillan]</td>\n",
       "      <td>[ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66</td>\n",
       "      <td>Det börjar bli vinter och kallt Då är det skön...</td>\n",
       "      <td>[Stefan Claesson]</td>\n",
       "      <td>[PRS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67</td>\n",
       "      <td>Sävsjö kommun ska få en ny skolchef Han heter ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>Ett signalfel på sträckan på fredagsmorgonen s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72</td>\n",
       "      <td>Stora grupper av pensionärer i är på krigsstig...</td>\n",
       "      <td>[Linus]</td>\n",
       "      <td>[PRS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>78</td>\n",
       "      <td>Ett test jdklsa jfkldsa sjfkldsaö jfklsdaöjfls...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>79</td>\n",
       "      <td>Testar 2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                               Text  \\\n",
       "0    2  Aktiespararna rekommenderar sina medlemmar att...   \n",
       "2    7  En man i 60 årsåldern föll ner i en grop som v...   \n",
       "3    8  En man i 60 årsåldern trillade ner i ett grävt...   \n",
       "4   56                        Här är den längre versionen   \n",
       "5   66  Det börjar bli vinter och kallt Då är det skön...   \n",
       "6   67  Sävsjö kommun ska få en ny skolchef Han heter ...   \n",
       "7   70  Ett signalfel på sträckan på fredagsmorgonen s...   \n",
       "8   72  Stora grupper av pensionärer i är på krigsstig...   \n",
       "9   78  Ett test jdklsa jfkldsa sjfkldsaö jfklsdaöjfls...   \n",
       "10  79                                           Testar 2   \n",
       "\n",
       "                  Entities      Labels  \n",
       "0   [Gunvor Group, Rörvik]  [PRS, ORG]  \n",
       "2                  [David]       [PRS]  \n",
       "3                       []          []  \n",
       "4         [Smålandsvillan]       [ORG]  \n",
       "5        [Stefan Claesson]       [PRS]  \n",
       "6                       []          []  \n",
       "7                       []          []  \n",
       "8                  [Linus]       [PRS]  \n",
       "9                       []          []  \n",
       "10                      []          []  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from spacy.pipeline.ner import EntityRecognizer\n",
    "from numpy import dtype\n",
    "import spacy\n",
    "from os.path import exists\n",
    "np.warnings.filterwarnings('error', category=np.VisibleDeprecationWarning) \n",
    "\n",
    "if(not exists('preprocessed_articles.csv')):\n",
    "    df_processed = df_articles.drop(columns=['Title']).copy()\n",
    "    nlp = spacy.load(\"sv_core_news_sm\")\n",
    "    labels_to_remove = ['LOC', 'TME']\n",
    "\n",
    "    # Does not seem to work?\n",
    "    #df_processed['Entities'] = np.empty((len(df_processed), 0)).tolist()\n",
    "\n",
    "    entity_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for index, row in df_articles.iterrows():\n",
    "        doc_text = nlp(row['Text'])\n",
    "        #doc_text = nlp(remove_labels(doc_text, labels=labels_to_remove))\n",
    "\n",
    "        doc_title = nlp(row['Title'])\n",
    "        #doc_title = nlp(remove_labels(doc_title, labels=labels_to_remove))\n",
    "\n",
    "        doc_ents = doc_text.ents + doc_title.ents\n",
    "\n",
    "        # Remove duplicate entities from the list\n",
    "        unique_ents = list({keyword.__repr__(): keyword for keyword in doc_ents}.values())\n",
    "        \n",
    "        #entity_list.add(str(unique_ents))\n",
    "        # Remove entities that have label 'TME' or 'LOC' because they are mostly redundant\n",
    "        # And the text will be changed to not contain words with these labels\n",
    "        unique_ents = [ent for ent in unique_ents if not ent.label_ in labels_to_remove]    \n",
    "           \n",
    "        entities = [str(x) for x in unique_ents]\n",
    "        labels = [str(labels.label_) for labels in unique_ents]\n",
    "        \n",
    "        # Remove words that contain the specified labels\n",
    "        label_free_text = remove_labels(doc_text, labels=labels_to_remove)\n",
    "     \n",
    "        entity_list.append(entities)\n",
    "        label_list.append(labels)\n",
    "        \n",
    "        df_processed.at[index,['Text']] = label_free_text\n",
    "        \n",
    "    df_processed['Entities'] = pd.Series(entity_list)\n",
    "    df_processed['Labels'] = pd.Series(label_list)\n",
    "\n",
    "    df_processed.to_csv('preprocessed_articles.csv')\n",
    "\n",
    "df_processed.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove empty rows and convert to lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not used so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Labels', 'Entities'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\repos\\TSTS22_NLP_Project\\project.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_test \u001b[39m=\u001b[39m df_articles[[\u001b[39m\"\u001b[39;49m\u001b[39mLabels\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mEntities\u001b[39;49m\u001b[39m\"\u001b[39;49m]]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor ind, row in df_test.iterrows():\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    if row[\"Labels\"] == \"[]\":\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdf_test[[\"Labels\",\"Entities\"]].apply(lambda x : str(x).split(','))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/repos/TSTS22_NLP_Project/project.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df_test\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\oskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Labels', 'Entities'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "df_test = df_articles[[\"Labels\",\"Entities\"]]\n",
    "\"\"\"\n",
    "for ind, row in df_test.iterrows():\n",
    "    if row[\"Labels\"] == \"[]\":\n",
    "        df_test = df_test.drop(index=ind)\n",
    "\n",
    "df_test[[\"Labels\",\"Entities\"]].apply(lambda x : str(x).split(','))\n",
    "\"\"\"\n",
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "882a6b7fc3ca80e688227decd54209862062b8721a918d514e0ed60576137ba8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
